## SmartCN

### 分词器说明

[Lucene](http://lucene.apache.org/)官方自带的分词器，基于HMM算法实现的。

### 分词器特性

1. 速度快

2. 准确度不高，可能需要重新训练样本

3. 

### 项目配置

**语料库**

hhmm文件下面的两个文件bigramdict.mem和coredict.mem是语料库。

**停用词**

停用词文件为stopwords.txt。

**扩展词**


### 项目使用

```java
// 申明Analyzer

```

### 作者信息

[新浪微博: 皮皮数据挖掘](http://www.weibo.com/u/1862087393 "新浪微博")

[微信: wgybzb](https://github.com/wgybzbrobot "微信")

[QQ: 1010437118](https://github.com/wgybzbrobot "QQ")

[邮箱: wgybzb@sina.cn](https://github.com/wgybzbrobot "邮箱")

[GitHub: wgybzbrobot](https://github.com/wgybzbrobot "GitHub首页")
